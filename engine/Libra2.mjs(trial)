// libra.mjs - PurpleBot AI Core (ESM + Genius AI Enhancements)
// Author: Dr. Sanne Karibo

// üîó Dependencies (ESM style)
import firebase from 'firebase/app';
import 'firebase/firestore';
import 'firebase/storage';

import * as tf from '@tensorflow/tfjs-node';
import zlib from 'zlib';
import path from 'path';
import { fileURLToPath } from 'url';
import { promises as fs } from 'fs';

// Node __dirname shim for ESM
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// üîê Firebase Initialization
const firebaseConfig = {
  apiKey: "AIzaSyD8KI5x8uvqyvmBDxNp7kmfkz9LJeYo49Q",
  authDomain: "libra-e615f.firebaseapp.com",
  projectId: "libra-e615f",
  storageBucket: "libra-e615f.appspot.com",
  messagingSenderId: "93883554914",
  appId: "1:93883554914:web:1aa7c95dc991184bd0053b"
};

const app = firebase.apps?.length ? firebase.app() : firebase.initializeApp(firebaseConfig);
const db = firebase.firestore(app);
const storage = firebase.storage(app);

// =======================
// üìä Market Classification
// =======================

export function classifyMarket(ticks) {
  const prices = ticks.map(t => t.quote);
  const diff = prices.slice(1).map((p, i) => p - prices[i]);
  const mean = diff.reduce((a, b) => a + b, 0) / diff.length;
  const volatility = Math.sqrt(diff.map(x => Math.pow(x - mean, 2)).reduce((a, b) => a + b, 0) / diff.length);
  if (volatility > 1.5) return 'volatile';
  if (Math.abs(mean) > 0.5) return 'trending';
  return 'ranging';
}

// =======================
// üß† Model Architecture (Genius AI Enhancements)
// =======================

function buildModel(hiddenLayers = [32, 16]) {
  const model = tf.sequential();
  model.add(tf.layers.dense({ units: hiddenLayers[0], activation: 'relu', inputShape: [4] }));
  for (let i = 1; i < hiddenLayers.length; i++) {
    model.add(tf.layers.dense({ units: hiddenLayers[i], activation: 'relu' }));
  }
  model.add(tf.layers.dense({ units: 1 }));
  model.compile({ optimizer: tf.train.adam(0.001), loss: 'meanSquaredError' });
  return model;
}

export async function trainShadowModel(echoBuffers) {
  const inputs = [], labels = [];

  for (const buffer of echoBuffers) {
    const echo = JSON.parse(zlib.gunzipSync(buffer));
    const features = echo.ticks.map(t => [t.open, t.high, t.low, t.close]);
    const closes = echo.ticks.map(t => t.close);
    inputs.push(...features);
    labels.push(...closes);
  }

  const inputTensor = tf.tensor2d(inputs);
  const labelTensor = tf.tensor1d(labels);
  const model = buildModel([64, 32, 16]);

  await model.fit(inputTensor, labelTensor, {
    epochs: 30,
    batchSize: 32,
    shuffle: true,
    verbose: 0
  });

  return model;
}

export async function getSparseWeights(baseModel, trainedModel) {
  const deltas = [];
  const baseWeights = baseModel.getWeights();
  const newWeights = trainedModel.getWeights();

  for (let i = 0; i < newWeights.length; i++) {
    const delta = tf.sub(newWeights[i], baseWeights[i]);
    const abs = tf.abs(delta);
    const mean = tf.mean(abs).arraySync();
    const threshold = mean * 2;

    const mask = tf.greater(abs, threshold);
    const sparseDelta = tf.mul(tf.cast(mask, 'float32'), delta);

    deltas.push({ id: i, shape: sparseDelta.shape, data: await sparseDelta.array() });
  }
  return deltas;
}

// =======================
// üíæ Storage
// =======================

export async function storeEcho(ticks, regime, outcome) {
  const compressed = zlib.gzipSync(JSON.stringify({ ticks, outcome }));
  const filePath = `echoes/${regime}/${Date.now()}.bin`;
  const fileRef = storage.ref(filePath);
  await fileRef.put(compressed);

  await db.collection('echoes_meta').doc(Date.now().toString()).set({
    regime,
    outcome,
    count: ticks.length
  });
  console.log(`[üß¨] Echo stored ‚Üí ${filePath}`);
}

export async function saveSparseModel(deltas, modelName = 'shadow') {
  const payload = JSON.stringify(deltas);
  const compressed = zlib.gzipSync(payload);
  const filename = `models/${modelName}/weights_sparse_latest.bin`;

  const fileRef = storage.ref(filename);
  await fileRef.put(compressed);
  console.log(`[üíæ] Saved ${modelName} model to Firebase`);
}

// =======================
// üîÆ Prediction
// =======================

export function flashUrgency(ticks) {
  const prices = ticks.map(t => t.quote);
  const vol = Math.sqrt(prices.map((v, i) => i > 0 ? Math.pow(v - prices[i - 1], 2) : 0).reduce((a, b) => a + b, 0) / prices.length);
  const momentum = prices.at(-1) - prices[0];

  if (Math.abs(momentum) > 0.2 && vol > 0.3) {
    return { urgency: 'NOW', confidence: Math.min(1, Math.abs(momentum) * 5) };
  }
  return { urgency: 'WAIT', confidence: 1 - vol };
}

export async function coreDirection(ticks) {
  const input = ticks.map(t => [t.open, t.high, t.low, t.close]);
  const model = buildModel();
  await loadSparseWeights(model, 'hunter');

  const output = model.predict(tf.tensor2d(input));
  const predClose = output.arraySync().pop();
  const lastClose = ticks.at(-1).close;
  const direction = predClose > lastClose ? 1 : -1;
  const tp = direction > 0 ? lastClose * 1.005 : lastClose * 0.995;

  return { direction, tp, predicted: predClose };
}

export function reflexDecision(core, flash) {
  const size = Math.min(1, flash.confidence * 0.8);
  const sl = core.direction > 0 ? core.tp * 0.996 : core.tp * 1.004;
  return {
    direction: core.direction,
    size: Number(size.toFixed(2)),
    tp: Number(core.tp.toFixed(3)),
    sl: Number(sl.toFixed(3)),
    confidence: Number(flash.confidence.toFixed(2))
  };
}

export async function loadSparseWeights(model, type = 'hunter') {
  const filePath = path.join(__dirname, `model/${type}/weights_sparse_latest.bin`);
  try {
    await fs.access(filePath);
    const compressed = await fs.readFile(filePath);
    const deltaData = JSON.parse(zlib.gunzipSync(compressed).toString());
    const weights = model.getWeights();

    const updated = weights.map((w, i) => {
      const delta = deltaData.find(d => d.id === i);
      return delta ? tf.add(w, tf.tensor(delta.data, delta.shape)) : w;
    });
    model.setWeights(updated);
  } catch (e) {
    console.warn(`[‚ö†Ô∏è] No sparse weights found for ${type}`);
  }
}

export async function runPrediction(ticks) {
  if (ticks.length < 300) throw new Error('Insufficient tick history');
  const flash = flashUrgency(ticks.slice(-50));
  if (flash.urgency !== 'NOW') return { action: 'WAIT', flash };

  const core = await coreDirection(ticks.slice(-300));
  const reflex = reflexDecision(core, flash);
  return { action: 'TRADE', flash, core, reflex };
}

// =======================
// üß¨ Evolution (future AI model self-reinforcement)
// =======================

export function batchTicks(data, size = 300) {
  const batches = [];
  for (let i = 0; i <= data.length - size; i += 10) {
    batches.push(data.slice(i, i + size));
  }
  return batches;
}

export async function evolveModels(totalTicks = 5000, regime = 'volatile') {
  console.log(`[üß†] Evolving model with ${totalTicks} ticks for ${regime} regime...`);

  const echoSequences = []; // TODO: await getEchoes(regime)
  const rawTicks = [];      // TODO: await deriv.getTicksForTraining(totalTicks)
  const batches = batchTicks(rawTicks, 300);
  const combined = echoSequences.concat(batches);
  const synthetic = [];     // TODO: generateSynthetic(combined)

  const tensorBoardCallback = tf.node.tensorBoard(`logs/train_${Date.now()}`);
  const shadowModel = {};   // TODO: await trainModel(synthetic, [tensorBoardCallback])
  const improvement = 0;    // TODO: await compareModels(shadowModel, 'hunter')

  if (improvement > 15) {
    await saveSparseModel(shadowModel, 'hunter');
    console.log('[üöÄ] Promoted shadow model to hunter');
  } else {
    console.log('[ü™∂] Shadow model not promoted');
  }
}

// =======================
// Export Firebase instances
// =======================

export { app, db, storage };
